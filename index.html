<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="How Do I Look?">
  <meta name="keywords" content="BLIP-2, GPT, OpenAI, Prompt Engineering">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>HDIL: How Do I Look?</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/tshirt.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

   <style>
    body {
            justify-content: center; /* Horizontally center */
        }

        #wrapper { 
    width: 920px; 
    height: auto; 
    margin: 0 auto;
} 
#home1 { 
    width: 30%; 
    height: 300px; 
    float: left; 
    margin-right: 5%;
} 

#home2 { 
    width: 30%; 
    height: 300px; 
    float: left; 
}

 #home3 { 
    width: 30%; 
    height: 300px; 
    float: left; 
}

.clear{
    clear: both;
}

@media (max-width:767px) {
    #wrapper{
        width: 100%;
        height: auto;
    }
    #home1 {
        width: 100%;
        height: auto;
        float: none;
    }
    #home2 {
        width: 100%;
        height: auto;
        float: none;
    }
    #home3 {
        width: 100%;
        height: auto;
        float: none;
    }
}
    </style>

  <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <!-- <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div> -->

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">HDIL: How Do I Look?</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://www.linkedin.com/in/dishani-lahiri/">Dishani Lahiri</a>,</span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/sayalikandarkar/">Sayali Kandarkar</a>,</span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/asmita-hajra/">Asmita Hajra,</a>
            </span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/pratik-mandlecha/">Pratik Mandlecha</a></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">Carnegie Mellon University</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/dishanil/HowDoiLook"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>

              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=uxJheKETTKI"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Video</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
<!--               <span class="link-block">
                <a href="https://github.com/neepacmu/ARF-svox2/blob/master/download_data.sh"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
              </span> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We present a <b>real-time</b> pipeline to generate <b>appropriateness</b> of an attire for any custom occasion or event. The pipeline also provides the user with suggestions when the attire can be improved to be more <b>culturally sensitive, suitable for the season, and color coordinated</b>. The pipeline consists of state-of-the-art image-to-text model, <a href=https://github.com/salesforce/LAVIS/tree/main/projects/blip2>BLIP-2</a>, to generate detailed descriptions of the person's attire in the image. Using this look description and the user-provided custom description of the event that they are dressed up for, we perform Prompt Engineering to develop the most impactful prompt to query <a href=https://openai.com/blog/gpt-3-5-turbo-fine-tuning-and-api-updates>GPT3.5-turbo</a> through OpenAI API calls. The resulting text consists of an "Overall Rating", sub-category ratings, and possible suggestions in attire and/or accessories. The user-interface is intuitive and the overall latency is <b>~7.1s</b>.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/dish_correct.png"
           class="interpolation-image"
           alt="Interpolate start reference image."/>
      <p class="subtitle has-text-centered">An image of Dishani in this attire with input prompt: 
        "for going to a snow resort"</p>

      <img src="./static/images/dish_okay.png"
           class="interpolation-image"
           alt="Interpolate start reference image."/>
      <p class="subtitle has-text-centered">
        An image of Dishani in this attire with input prompt: "for an Indian wedding"
        </p>
    </div>
  </div>
</section>
<!-- 
<div class="container">
  <div class="video-container">
      <video controls>
           <source src="./static/videos/room_table141_chair15.mp4"
                      type="video/mp4">
          Your browser does not support the video tag.
      </video>
  </div>
  <div class="video-container">
      <video controls>
           <source src="./static/videos/room_table141_chair15.mp4"
                      type="video/mp4">
          Your browser does not support the video tag.
      </video>
  </div>
</div> -->
    
<!-- <section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Stylized NeRFs</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="200%">
            <source src="./static/videos/room_table141_chair15.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="200%">
            <source src="./static/videos/room_tv133_table131_chair19.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="200%">
            <source src="./static/videos/room_table131_tv19.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="200%">
            <source src="./static/videos/room_table133_chair131.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Pipeline</h2>
        <div class="content has-text-justified">
          <p>
            The real-time pipeline consists of the following steps: <br>
            <br>
            <b>Step 1:</b> User uploads an image of themselves in an attire and the occasion they are dressed up for. <br>
            <br>
            <b>Step 2:</b> The image is passed through a state-of-the-art image-to-text model, BLIP-2, to generate a detailed description of the person's attire in the image. <br>
            <br>
            <b>Step 3:</b> Using this look description and the user-provided custom description of the event that they are dressed up for, we perform Prompt
            Engineering to develop the most impactful prompt to query GPT3.5-turbo through OpenAI API calls. We decided on the following factors to construct the prompt for the query:
            Color coordination,  Color appropriateness, Potential cultural sensitivity, Seasonal suitability, accessories.<br>
            <br>
            <b>Step 4:</b> The resulting text consists of an "Overall Rating", sub-category ratings, and possible suggestions in attire and/or accessories. <br>
            <br>
            An example prompt to the <b>BLIP-2</b> model is -> <br>
            <code>
              "Question: Explain the outfit in as much detail as possible. Answer:"<br>
            </code>

            <br>
            An example prompt to the <b>GPT3.5-turbo</b> model after <b>Prompt Engineering</b> is -> <br>
            <code>
            I am a male, wearing a navy blue and gold embroidered kurta pajama. Details of the occasion are as follows:
              attending a close friend's Indian wedding. Give one overall rating out of
            'consider changing outfit', 'could be better', 'on point', and title it 'overall rating'. Consider:
            Color coordination,  Color appropriateness, Potential cultural sensitivity, Seasonal suitability, accessories (for each of the categories give one succinct sentence.
            </code>
          </p>
        </div>
      </div>
    </div>
    
<div id="wrapper">
    <img src="./static/images/pipeline.jpeg"
       class="interpolation-image"
       alt="Interpolate start reference image."/>
    <div class="clear"></div>
</div>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3"></h2>
        <h2 class="title is-3">Results</h2>
        <div class="content has-text-justified">
          <p>
            We obtained the best results when we used BLIP-2 as the image-to-text generation model along with GPT3.5-turbo as the LLM. 
            We leverage the quality of the generated texts from these large models pre-trained on huge and diverse datasets. <br>
            <br>
            The latency of the whole pipeline is only <b>~7.1 s</b>. <br>
            <br>
            We observe that more than 90% of the time is actually taken by the OpenAI 
            API calls. This can be easily reduced by using pre-saved open-source models like any version of LLaMA2.

            Below are some examples showcasing 2 different attires and occasions. 

          </p>
        </div>
        <section class="hero teaser">
          <div class="container is-max-desktop">
            <div class="hero-body">
              <img src="./static/images/result_Indian_wedding.jpeg"
                   class="interpolation-image"
                   alt="Interpolate start reference image."/>
        
              <h2 class="subtitle has-text-centered">
                <span class="dnerf">  
              </h2>

              <img src="./static/images/result_thai_wedding.png"
                  class="interpolation-image"
                  alt="Interpolate start reference image."/>

              <h2 class="subtitle has-text-centered">
                <span class="dnerf"> 
              </h2>
            </div>
          </div>
        </section>
      </div>
    </div>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3"></h2>
          <h2 class="title is-3">Ablation Studies</h2>
          <div class="content has-text-justified">
            <h3>Why not use BLIP-2 directly?</h3>
            <p>
              Here is an example case which showcases that although BLIP is great at describing the image and captioning it, it is not reliable when answering indirect or chain of thought questions about the objects in the image.
              <br><br>
              This is because, the text prompt that we provide is simply appended to the frozen LLM when we query it. So, it is stifled 
              by the amount of Prompt Engineering that takes place and the quality of the LLM. 

            </p>
          </div>
          <img src="./static/images/blip2_error.jpeg"
               class="interpolation-image"
               alt="Interpolate start reference image."/>
        </div>
      </div>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3"></h2>
          <h2 class="title is-3">Future Scope</h2>
          <div class="content has-text-justified">
            <p>
              <p>
              <h4>Experiment with LLaMA2 as the frozen LLM:</h4> 
              </p>
              The authors of BLIP-2 mention that they have observed improved generations when improving the image encoders and/or the 
              frozen LLM. Thus, using a higher quality LLM that has been proven to answer deduction-based questions reliably should 
              boost the performance of the image-to-text model itself to hopefully eliminate the need for using GPT3.5-turbo.
            </p>
            <p>
              <h4>Real-time Image Analysis: </h4>
            </p>
            <p>
              Implement a system that can analyze images in real-time. This could be particularly useful for event planners, social media platforms, or e-commerce sites looking to ensure the content shared aligns with their guidelines.
            </p>
            
            <h4>Virtual Wardrobe:</h4>
              
            <p>
              Integrate a virtual wardrobe feature that suggests alternative outfits for images that may not be appropriate for a given context. Users can virtually try on different outfits generated by the AI
            </p>
          </div>
        </div>
      </div>

</body>
</html>
